{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "nbTranslate": {
      "displayLangs": [
        "*"
      ],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "en",
      "targetLang": "fr",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "nlp_2-1_text_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LGamZ8S_zyb"
      },
      "source": [
        "# **Text-Summarization**\n",
        "\n",
        "Text summarizer can give a short summary of a large text. <br>\n",
        "[SpaCy](www.spacy.io) together with [pyTextRank](https://github.com/DerwenAI/pytextrank) have a text summriziation model which is presented in this notebook.\n",
        "\n",
        "The following example is based on that code-snippet for pytextrank: [derwin.ai](https://derwen.ai/docs/ptr/explain_summ/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xavxSpS-f3CI"
      },
      "source": [
        "#### Install additional libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQIo1p4uAC8C"
      },
      "source": [
        "!pip install pytextrank==3.0.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhdAZJnug3T8"
      },
      "source": [
        "# download language model for spacy\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9HsF9N9igEwQ"
      },
      "source": [
        "#### Load resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcW1TC8xrynl"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pa3QK56i_zyx"
      },
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "sp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upP_NK5B_zy1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "025596b7-8e45-4790-bede-49470c613d08"
      },
      "source": [
        "# prepare pipeline\n",
        "sp.add_pipe('textrank', last=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pytextrank.base.BaseTextRank at 0x7f52462466d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijhBuc6be9bz"
      },
      "source": [
        "#### Basic Text-Summarization example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKOHaC9Me80Z"
      },
      "source": [
        "# Create sample text as SpaCy instance\n",
        "doc = sp(\n",
        "    \"Mr. and Mrs. Dursley, of number four, Private Drive, were proud to say \\\n",
        "they were perfectly normal, thank you very much. They were the last people you'd expect \\\n",
        "to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\"\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOffQTR7od4X",
        "outputId": "b2852e9a-1969-4370-8b41-26a4639d477c"
      },
      "source": [
        "# Print the noun chunks of the sample text\n",
        "for chunks in doc.noun_chunks:\n",
        "  print(chunks)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mr. and Mrs. Dursley\n",
            "number\n",
            "Private Drive\n",
            "they\n",
            "you\n",
            "They\n",
            "the last people\n",
            "you\n",
            "anything\n",
            "they\n",
            "such nonsense\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSRfycdlpBjg",
        "outputId": "f499ba22-b8af-4351-f0b3-3d04e4b0e2a0"
      },
      "source": [
        "# Print entities of the document\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.label_, ent.start, ent.end)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dursley PERSON 3 4\n",
            "number four CARDINAL 6 8\n",
            "Private Drive FAC 9 11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwC3SusLqI3Y",
        "outputId": "839b9eaa-788c-41bb-fd93-18a1bcf893e1"
      },
      "source": [
        "# Show top rated phrases\n",
        "\n",
        "# Iterate through each sentence in the doc, constructing a\n",
        "# [*lemma graph*](https://derwen.ai/docs/ptr/glossary/#lemma-graph),\n",
        "# then returning the top-ranked phrases.\n",
        "\n",
        "for p in doc._.phrases:\n",
        "    print(\"{:.4f} {:5d}  {}\".format(p.rank, p.count, p.text))\n",
        "    print(p.chunks)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2058     1  such nonsense\n",
            "[such nonsense]\n",
            "0.1477     2  Private Drive\n",
            "[Private Drive, Private Drive]\n",
            "0.1000     1  number\n",
            "[number]\n",
            "0.0883     1  Dursley\n",
            "[Dursley]\n",
            "0.0697     1  Mr. and Mrs. Dursley\n",
            "[Mr. and Mrs. Dursley]\n",
            "0.0520     1  the last people\n",
            "[the last people]\n",
            "0.0462     1  number four\n",
            "[number four]\n",
            "0.0000     1  They\n",
            "[They]\n",
            "0.0000     1  anything\n",
            "[anything]\n",
            "0.0000     2  they\n",
            "[they, they]\n",
            "0.0000     2  you\n",
            "[you, you]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVUNK5qQqORa",
        "outputId": "562439d7-d576-4c56-f388-423e619f63a7"
      },
      "source": [
        "# Construct a list of the sentence boundaries with a phrase-vector (initialized to empty set) for each sentence.\n",
        "sent_bounds = [ [s.start, s.end, set([])] for s in doc.sents ]\n",
        "print(sent_bounds)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 26, set()], [26, 53, set()]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1EI-aHeqUNu",
        "outputId": "41953ef1-145b-4a9e-99e1-9d149ee21e8b"
      },
      "source": [
        "# Iterate through the top-ranked phrases and add them to the \n",
        "# phrase-vector for each sentence.\n",
        "\n",
        "limit_phrases = 4\n",
        "\n",
        "phrase_id = 0\n",
        "unit_vector = []\n",
        "\n",
        "for p in doc._.phrases:\n",
        "    print(phrase_id, p.text, p.rank)\n",
        "\n",
        "    unit_vector.append(p.rank)\n",
        "\n",
        "    for chunk in p.chunks:\n",
        "        #print(\" \", chunk.start, chunk.end)\n",
        "\n",
        "        for sent_start, sent_end, sent_vector in sent_bounds:\n",
        "            if chunk.start >= sent_start and chunk.end <= sent_end:\n",
        "                #print(\" \", sent_start, chunk.start, chunk.end, sent_end)\n",
        "                sent_vector.add(phrase_id)\n",
        "                break\n",
        "\n",
        "    phrase_id += 1\n",
        "\n",
        "    if phrase_id == limit_phrases:\n",
        "        break"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 such nonsense 0.20578727368601007\n",
            "1 Private Drive 0.1476932514643156\n",
            "2 number 0.10003737208485038\n",
            "3 Dursley 0.08830619471948406\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-2d6_Yuqitq",
        "outputId": "8582bdd9-3b8f-4bf6-bd35-e0a76c29fc66"
      },
      "source": [
        "# Show the results\n",
        "\n",
        "# Look at the sentence boundaries with its phrase-vector\n",
        "print(sent_bounds)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 26, {1, 2, 3}], [26, 53, {0}]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfN0utbbq5By",
        "outputId": "eb7e75b5-8938-4974-be91-400e66ad590a"
      },
      "source": [
        "# We also construct a unit_vector for all of the phrases, up to the limit requested.\n",
        "print(unit_vector)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.20578727368601007, 0.1476932514643156, 0.10003737208485038, 0.08830619471948406]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WZJJnUBq6XH",
        "outputId": "f471f932-8719-47ff-9805-fbfd64b058d4"
      },
      "source": [
        "# Nomralize the unit_vector\n",
        "sum_ranks = sum(unit_vector)\n",
        "unit_vector = [ rank/sum_ranks for rank in unit_vector ]\n",
        "\n",
        "unit_vector"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37980458370468767,\n",
              " 0.2725852424381945,\n",
              " 0.18463071976729584,\n",
              " 0.1629794540898221]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-a65t24q_cP",
        "outputId": "730b2c9e-e427-42d2-fc7d-7875629e18de"
      },
      "source": [
        "# Iterate through each sentence, calculating its euclidean distance from the unit vector.\n",
        "\n",
        "from math import sqrt\n",
        "\n",
        "sent_rank = {}\n",
        "sent_id = 0\n",
        "\n",
        "for sent_start, sent_end, sent_vector in sent_bounds:\n",
        "    #print(sent_vector)\n",
        "    sum_sq = 0.0\n",
        "\n",
        "    for phrase_id in range(len(unit_vector)):\n",
        "        #print(phrase_id, unit_vector[phrase_id])\n",
        "\n",
        "        if phrase_id not in sent_vector:\n",
        "            sum_sq += unit_vector[phrase_id]**2.0\n",
        "\n",
        "    sent_rank[sent_id] = sqrt(sum_sq)\n",
        "    sent_id += 1\n",
        "\n",
        "print(sent_rank)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 0.37980458370468767, 1: 0.3673602040672008}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "du23UfWMrGE5",
        "outputId": "5de5cafc-32f9-43e9-fd9d-1791728724e8"
      },
      "source": [
        "# Sort the sentence indexes in descending order\n",
        "from operator import itemgetter\n",
        "\n",
        "sorted(sent_rank.items(), key=itemgetter(1)) "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, 0.3673602040672008), (0, 0.37980458370468767)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tZyjO0krJbk",
        "outputId": "a7632a14-015a-407e-e124-0c51b063b331"
      },
      "source": [
        "# Extract the sentences with the lowest distance, up to the limit requested.\n",
        "limit_sentences = 2\n",
        "\n",
        "sent_text = {}\n",
        "sent_id = 0\n",
        "\n",
        "for sent in doc.sents:\n",
        "    sent_text[sent_id] = sent.text\n",
        "    sent_id += 1\n",
        "\n",
        "num_sent = 0\n",
        "\n",
        "for sent_id, rank in sorted(sent_rank.items(), key=itemgetter(1)):\n",
        "    print(sent_id, sent_text[sent_id])\n",
        "    num_sent += 1\n",
        "\n",
        "    if num_sent == limit_sentences:\n",
        "        break"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 They were the last people you'd expect to be involved in anything strange or mysterious, because they just didn't hold with such nonsense.\n",
            "0 Mr. and Mrs. Dursley, of number four, Private Drive, were proud to say they were perfectly normal, thank you very much.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2oMgGVZAivX"
      },
      "source": [
        "Copyright Â© 2021 IUBH Internationale Hochschule"
      ]
    }
  ]
}
